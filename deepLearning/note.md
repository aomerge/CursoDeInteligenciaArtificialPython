# Deep Learning

## Un recorido histórico por la evolucion del internet y la inteligencia artificial
La inteligencia artificial es una rama de la informática que se encarga de desarrollar algoritmos y sistemas que permiten a las máquinas realizar tareas que requieren de la inteligencia humana. La inteligencia artificial se ha desarrollado a lo largo de los años y ha evolucionado de manera significativa. En la actualidad, la inteligencia artificial se ha convertido en una herramienta fundamental en muchos campos, como la medicina, la robótica, la industria y la educación.

La inteligencia artificial se ha desarrollado a lo largo de los años y ha evolucionado de manera significativa. En la actualidad, la inteligencia artificial se ha convertido en una herramienta fundamental en muchos campos, como la medicina, la robótica, la industria y la educación.

## ¿Qué es el deep learning?

El deep learning es una rama de la inteligencia artificial que se encarga de desarrollar algoritmos y sistemas que permiten a las máquinas aprender de manera autónoma a partir de los datos. El deep learning se basa en la creación de redes neuronales artificiales que imitan el funcionamiento del cerebro humano y que son capaces de aprender de manera autónoma a partir de los datos.

El deep learning se ha convertido en una herramienta fundamental en muchos campos, como la medicina, la robótica, la industria y la educación. El deep learning se ha convertido en una herramienta fundamental en muchos campos, como la medicina, la robótica, la industria y la educación.

### ¿Quién inventó el deep learning?

![Deep learning](https://encrypted-tbn1.gstatic.com/licensed-image?q=tbn:ANd9GcTNpkK-T4PsS3zP-nC4YVCO1i8S2j5hG1X4ud1gFkTyc03Edh9qPKlGsbHYPQqwUvSGzq5EpN0aJBY07hQ)

El deep learning fue inventado por Geoffrey Hinton, un científico de la computación y psicólogo cognitivo canadiense. Hinton es considerado uno de los padres del deep learning y ha sido fundamental en el desarrollo de esta tecnología. Hinton ha realizado importantes contribuciones en el campo de la inteligencia artificial y ha sido reconocido con varios premios y distinciones por su trabajo.


### Las neuronas artificiales
![Nurona artificial](https://www.uaeh.edu.mx/divulgacion-ciencia/redes-neuronales/1.jpg)

Las neuronas artificiales son la unidad básica de las redes neuronales artificiales. Las neuronas artificiales son unidades computacionales que reciben una serie de entradas, realizan un cálculo y generan una salida. Las neuronas artificiales se organizan en capas y se conectan entre sí para formar una red neuronal artificial.

Las neuronas artificiales se organizan en capas y se conectan entre sí para formar una red neuronal artificial. Las neuronas artificiales se organizan en capas y se conectan entre sí para formar una red neuronal artificial.

## Entendamos el funcionamiento de las neuronas.
Las neuronas son las células del sistema nervioso que se encargan de transmitir la información a través de señales eléctricas y químicas. Las neuronas se organizan en redes y se conectan entre sí para formar circuitos neuronales que permiten al cerebro procesar la información y realizar funciones cognitivas.

![Neurona](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTLUfT6ZEHXr1Wbr8D6-sjt3xxZVPitmLE8rfHxFKouVQ&s)

Las neuronas se organizan en redes y se conectan entre sí para formar circuitos neuronales que permiten al cerebro procesar la información y realizar funciones cognitivas. Las neuronas se organizan en redes y se conectan entre sí para formar circuitos neuronales que permiten al cerebro procesar la información y realizar funciones cognitivas.

## La parte tecnica
Las neuronas reciben una serie de señales de entrada, las procesan y generan una señal de salida. Las neuronas se organizan en capas y se conectan entre sí para formar una red neuronal. Las redes neuronales son sistemas computacionales que imitan el funcionamiento del cerebro humano y que son capaces de aprender de manera autónoma a partir de los datos.

Las redes neuronales son sistemas computacionales que imitan el funcionamiento del cerebro humano y que son capaces de aprender de manera autónoma a partir de los datos. Las redes neuronales son sistemas computacionales que imitan el funcionamiento del cerebro humano y que son capaces de aprender de manera autónoma a partir de los datos.

![Red neuronal](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSCMCgm9hqXB7BuKGyoL-hF-9IX06DQsl0aerlkbDdRjg&s)

### Estandarizar y normalizar los datos

La estandarización y normalización de los datos es un proceso que se utiliza para transformar los datos de manera que tengan una distribución normal y sean comparables entre sí. La estandarización y normalización de los datos es un proceso que se utiliza para transformar los datos de manera que tengan una distribución normal y sean comparables entre sí.

Cada una de las señales son una variable independiente que se multiplica por un peso y se suman todas las señales de entrada. La suma de las señales de entrada se pasa por una función de activación que determina la salida de la neurona. La salida de la neurona se pasa a la siguiente neurona de la red neuronal.

### Sinapsis
Las sinapsis son las conexiones entre las neuronas que permiten la transmisión de las señales eléctricas y químicas. Las sinapsis son las conexiones entre las neuronas que permiten la transmisión de las señales eléctricas y químicas. Las sinapsis son las conexiones entre las neuronas que permiten la transmisión de las señales eléctricas y químicas.

### Función de Activación
La función de activación es una función matemática que se aplica a la suma de las señales de entrada de una neurona para determinar su salida. La función de activación es una función matemática que se aplica a la suma de las señales de entrada de una neurona para determinar su salida. La función de activación es una función matemática que se aplica a la suma de las señales de entrada de una neurona para determinar su salida.

### Tipo de Funciones de Activación:

1. *Función escalón*: La función escalón es una función matemática que toma un valor de 0 si la entrada es menor que cero y un valor de 1 si la entrada es mayor o igual a cero.
$$ f(z) = \begin{cases} 0 & \text{si } z < 0 \\ 1 & \text{si } z \geq 0 \end{cases} $$

2. *Función sigmoide*: La función sigmoide es una función matemática que toma un valor entre 0 y 1 y se utiliza para modelar la probabilidad de que una neurona se active.
$$ f(z) = \frac{1}{1 + e^{-z}} $$

3. *Función tangente hiperbólica*: La función tangente hiperbólica es una función matemática que toma un valor entre -1 y 1 y se utiliza para modelar la probabilidad de que una neurona se active.
$$ f(z) = \frac{e^z - e^{-z}}{e^z + e^{-z}} $$

4. *Función ReLU*: La función ReLU es una función matemática que toma un valor de cero si la entrada es menor que cero y un valor de la entrada si la entrada es mayor o igual a cero.
$$ f(z) = \max(0, z) $$

5. *Función Softmax*: La función Softmax es una función matemática que toma un vector de valores y los normaliza para que sumen uno. La función Softmax se utiliza para modelar la probabilidad de que una neurona se active.
$$ f(z) = \frac{e^z}{\sum_{i=1}^{n} e^{z_i}} $$

### Señal de salida
La señal de salida de una neurona es el resultado de la función de activación aplicada a la suma de las señales de entrada. La señal de salida de una neurona es el resultado de la función de activación aplicada a la suma de las señales de entrada. La señal de salida de una neurona es el resultado de la función de activación aplicada a la suma de las señales de entrada.

### Tecnica del gradiente descendente
La técnica del gradiente descendente es un algoritmo de optimización que se utiliza para ajustar los pesos de una red neuronal de manera que minimice el error de predicción. La técnica del gradiente descendente es un algoritmo de optimización que se utiliza para ajustar los pesos de una red neuronal de manera que minimice el error de predicción. La técnica del gradiente descendente es un algoritmo de optimización que se utiliza para ajustar los pesos de una red neuronal de manera que minimice el error de predicción.
$$ w = w - \alpha \nabla E $$

### La capa oculata
La capa oculta es una capa intermedia de una red neuronal que se encuentra entre la capa de entrada y la capa de salida. La capa oculta es una capa intermedia de una red neuronal que se encuentra entre la capa de entrada y la capa de salida. La capa oculta es una capa intermedia de una red neuronal que se encuentra entre la capa de entrada y la capa de salida.

Esto lo logra mediante los siguientes pasos:

1. En este primer paso se inicializan los pesos de la red neuronal de manera aleatoria. Los pesos son los valores que se multiplican por las señales de entrada para determinar la salida de la neurona. $$ w = np.random.rand(n) $$

2. Calcular la salida de la red neuronal aplicando la función de activación a la suma de las señales de entrada. Con la formula: $z = np.dot(w, x) + b$ donde w es el vector de pesos, x es el vector de entradas y b es el sesgo.

3. Calcular el error de predicción de la red neuronal. El error de predicción es la diferencia entre la salida real y la salida predicha por la red neuronal. $$ E = y - \hat{y} $$

4. Ajustar los pesos de la red neuronal utilizando la técnica del gradiente descendente. La técnica del gradiente descendente consiste en ajustar los pesos de la red neuronal en la dirección que minimice el error de predicción. $$ w = w - \alpha \nabla E $$

5. Repetir los pasos 2, 3 y 4 hasta que el error de predicción sea lo suficientemente pequeño.

## ¿Cómo funciona una red neuronal?
Este es un ejemplo de cómo funciona una red neuronal:
 * Una regresión lineal como red neuronal: Este tipo de red neuronal se utiliza para predecir un valor numérico a partir de un conjunto de variables de entrada. La regresión lineal es un modelo matemático que se utiliza para predecir un valor numérico a partir de un conjunto de variables de entrada. La regresión lineal se basa en la relación lineal entre las variables de entrada y la variable de salida. La regresión lineal se basa en la relación lineal entre las variables de entrada y la variable de salida. La regresión lineal se basa en la relación lineal entre las variables de entrada y la variable de salida.

 $$ y = w_1x_1 + w_2x_2 + w_3x_3  $$

 * Red neuronal en capas: Este tipo de red neuronal se utiliza para predecir un valor numérico a partir de un conjunto de variables de entrada. La red neuronal en capas es un modelo matemático que se utiliza para predecir un valor numérico a partir de un conjunto de variables de entrada. La red neuronal en capas se basa en la relación no lineal entre las variables de entrada y la variable de salida. La red neuronal en capas se basa en la relación no lineal entre las variables de entrada y la variable de salida. La red neuronal en capas se basa en la relación no lineal entre las variables de entrada y la variable de salida.

 $$ y = f(w_1x_1 + w_2x_2 + w_3x_3 + b) $$

##  Programacion clasica vs redes neuronales
La programación clásica se basa en la creación de algoritmos y sistemas que permiten a las máquinas realizar tareas de manera determinista. La programación clásica se basa en la creación de algoritmos y sistemas que permiten a las máquinas realizar tareas de manera determinista. La programación clásica se basa en la creación de algoritmos y sistemas que permiten a las máquinas realizar tareas de manera determinista.

Mientras que las redes neuronales se basan en la creación de algoritmos y sistemas que permiten a las máquinas aprender de manera autónoma a partir de los datos. Las redes neuronales se basan en la creación de algoritmos y sistemas que permiten a las máquinas aprender de manera autónoma a partir de los datos. Las redes neuronales se basan en la creación de algoritmos y sistemas que permiten a las máquinas aprender de manera autónoma a partir de los datos.

## Un Perceptron
El perceptrón es un modelo matemático de una neurona artificial que se utiliza para realizar tareas de clasificación. El perceptrón es un modelo matemático de una neurona artificial que se utiliza para realizar tareas de clasificación. El perceptrón es un modelo matemático de una neurona artificial que se utiliza para realizar tareas de clasificación.

El perceptrón se basa en la suma de las señales de entrada multiplicadas por los pesos de la neurona. La suma de las señales de entrada se pasa por una función de activación que determina la salida de la neurona. La salida de la neurona es la clase a la que pertenece el objeto de entrada.

### Funcion de coste
La función de coste es una función matemática que se utiliza para medir el error de predicción de una red neuronal. La función de coste es una función matemática que se utiliza para medir el error de predicción de una red neuronal. La función de coste es una función matemática que se utiliza para medir el error de predicción de una red neuronal.
$$ J(w) = \frac{1}{m} \sum_{i=1}^{m} (y_i - \hat{y}_i)^2 $$


## El metodo de optimizacion del gradiente descendente
El método de optimización del gradiente descendente es un algoritmo de optimización que se utiliza para ajustar los pesos de una red neuronal de manera que minimice la función de coste. El método de optimización del gradiente descendente es un algoritmo de optimización que se utiliza para ajustar los pesos de una red neuronal de manera que minimice la función de coste. El método de optimización del gradiente descendente es un algoritmo de optimización que se utiliza para ajustar los pesos de una red neuronal de manera que minimice la función de coste.

$$ w = w - \alpha \nabla J(w) $$

### Parámetros
* Tasa de aprendizaje (η): Es un hiperparámetro crucial que determina el tamaño del paso en cada actualización. Una tasa muy alta puede llevar a la divergencia, mientras que una muy baja puede resultar en una convergencia lenta.

* Número de iteraciones: Define cuántas veces se actualizará el modelo. Demasiadas iteraciones pueden llevar a sobreajuste, especialmente si la tasa de aprendizaje es muy baja.

### Consideraciones de Implementación
* Convergencia: Se debe monitorear la función de coste durante el entrenamiento para asegurarse de que el algoritmo está convergiendo.

* Escalado de características: Es recomendable escalar las características para que el descenso de gradiente funcione de manera más efectiva.

* Inicialización de parámetros: Los valores iniciales de θ pueden afectar la convergencia del algoritmo.

### Ventajas
* Generalidad: El Descenso de Gradiente puede aplicarse a cualquier función diferenciable, lo que lo hace muy versátil.

* Eficiencia: Es más eficiente que los métodos de optimización que requieren el cálculo de segundas derivadas.

### Desventajas
* Selección de hiperparámetros: La elección de la tasa de aprendizaje y el número de iteraciones puede ser desafiante.

* Mínimos locales: En funciones no convexas, el algoritmo puede quedar atrapado en mínimos locales en lugar de encontrar el mínimo global.

### Aplicaciones
* Utilizado en una variedad de campos, desde el aprendizaje automático hasta la economía, el Descenso de Gradiente es esencial para optimizar funciones objetivo complejas, especialmente en el entrenamiento de modelos donde el cálculo analítico del mínimo no es factible.

### Por fuerza bruta
El metodo por fuerza bruta es un metodo de optimizacion que se utiliza para ajustar los pesos de una red neuronal probando todas las combinaciones posibles de pesos y seleccionando la que minimice la funcion de coste. En redes neuronales con muchas capas y neuronas, el metodo de optimizacion del gradiente descendente por fuerza bruta puede ser muy lento y costoso computacionalmente. 

## Gradiante descendente estocastico
El Descenso de Gradiente Estocástico (SGD) es un método de optimización utilizado para minimizar una función objetivo, comúnmente la función de pérdida en el contexto del aprendizaje automático. A diferencia del descenso de gradiente tradicional, que utiliza todo el conjunto de datos para calcular el gradiente de la función de pérdida, el SGD actualiza los parámetros utilizando solo un subconjunto aleatorio de los datos en cada iteración.

### Fórmula de Actualización
La actualización de los parámetros en el SGD se realiza de acuerdo con la siguiente fórmula:

$$ θ new =θold −η⋅∇ θ J(θ;x (i) ,y (i))$$

Donde:

* Parámetros del modelo.
$$ θ $$
* Tasa de aprendizaje.
$$ η $$
* Gradiente de la función de pérdida respecto a los parámetros 
θ, calculado en el i-ésimo subconjunto del conjunto de datos.
$$ ∇ θ​J(θ;x (i),y (i)) $$ 

### Consideraciones de Implementación
* Inicialización: La elección de los valores iniciales de θ puede influir significativamente en la convergencia y en la calidad de la solución encontrada.

* Decaimiento de la tasa de aprendizaje: Implementar un decaimiento de la tasa de aprendizaje puede ayudar a mejorar la convergencia, haciendo que el tamaño del paso disminuya a lo largo del tiempo.

* Regularización: La adición de términos de regularización puede prevenir el sobreajuste y mejorar la generalización del modelo.
### Ventajas 
* Eficiencia: El SGD es computacionalmente menos costoso por iteración que el descenso de gradiente tradicional, especialmente en conjuntos de datos grandes.

* Escalabilidad: Permite el entrenamiento de modelos en conjuntos de datos que no caben en memoria, procesando un subconjunto a la vez.

* Convergencia en práctica: A pesar de la naturaleza "ruidosa" de las actualizaciones, el SGD a menudo converge más rápidamente en términos prácticos (tiempo real) en comparación con el descenso de gradiente tradicional.

### Desventajas
* Convergencia: El camino hacia la convergencia puede ser "ruidoso" debido a la naturaleza estocástica de las actualizaciones.

* Ajuste de Hiperparámetros: Requiere un cuidadoso ajuste de la tasa de aprendizaje y, potencialmente, otros hiperparámetros como el tamaño del lote y el decaimiento de la tasa.

### Aplicaciones
El SGD se utiliza ampliamente en la optimización de modelos de aprendizaje automático, especialmente en contextos donde la eficiencia computacional es crucial y los conjuntos de datos son grandes.

## Propagacoion hacia atras
La propagación hacia atrás, o backpropagation, es un algoritmo esencial en el entrenamiento de redes neuronales. Utiliza el cálculo de derivadas para ajustar los pesos de la red de manera que el error de salida se minimice. Específicamente, aplica la regla de la cadena del cálculo diferencial para computar el gradiente de la función de pérdida respecto a cada peso en la red, propagando el error desde la capa de salida hacia las capas de entrada.

### Funcionamiento
* Forward Pass: Se realiza una pasada hacia adelante (forward pass) calculando las activaciones en cada capa hasta obtener la salida de la red.

* Cálculo del Error: Se calcula la diferencia entre la salida obtenida y la salida deseada utilizando una función de pérdida.

* Backward Pass: Se realiza una pasada hacia atrás (backward pass) donde se calculan los gradientes de la función de pérdida respecto a cada peso, aplicando la regla de la cadena para propagar el error desde la salida hacia las capas anteriores.

* Actualización de Pesos: Los pesos se actualizan en dirección opuesta al gradiente, típicamente utilizando un algoritmo de optimización como el descenso de gradiente o sus variantes.

### Fórmula de Actualización
$$ w = w −η* \frac{∂J}{∂w} $$
Donde:
* w: Peso a actualizar.
* η: Tasa de aprendizaje.
* J: Función de pérdida.
* ∂J/∂w: Gradiente de la función de pérdida respecto al peso w.

### Parámetros
Tasa de aprendizaje (η): Determina el tamaño del paso en la actualización de los pesos. Una tasa inadecuada puede llevar a convergencia lenta o divergencia.

Función de Pérdida: Define cómo se calcula la diferencia entre la salida de la red y la salida esperada. Ejemplos comunes incluyen el error cuadrático medio y la entropía cruzada.

### Aplicaciones
La propagación hacia atrás es fundamental en el entrenamiento de redes neuronales, aplicándose en una amplia gama de tareas como clasificación, regresión, reconocimiento de patrones, y aprendizaje profundo en general.